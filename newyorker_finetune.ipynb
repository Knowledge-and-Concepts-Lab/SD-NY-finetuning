{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipSgY-L3z8kG"
      },
      "source": [
        "# Fine Tune Stable Diffusion\n",
        "\n",
        "Fine tuning Stable Diffusion on Pokemon, \n",
        "for more details see the [Lambda Labs examples repo](https://github.com/LambdaLabsML/examples). \n",
        "\n",
        "We recommend using a multi-GPU machine, for example an instance from [Lambda GPU Cloud](https://lambdalabs.com/service/gpu-cloud). If running on Colab this notebook is likely to need a GPU with >16GB of VRAM and a runtime with high RAM, which will almost certainly need Colab Pro or Pro+. (If you get errors suchs as `Killed` or `CUDA out of memory` then one of these is not sufficient)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bjNGOU6Pz8kH"
      },
      "source": [
        "### If running as a nb ,this nb should be in the root dir of your stablediffusion repo to make sure paths are correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m1AkWL270DSE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Apr 29 02:48:19 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  On   | 00000000:5E:00.0 Off |                  N/A |\n",
            "| 30%   31C    P8    23W / 350W |  15566MiB / 24576MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA GeForce ...  On   | 00000000:AF:00.0 Off |                  N/A |\n",
            "| 30%   30C    P8    17W / 350W |   1830MiB / 24576MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A    690721      C   python                          15117MiB |\n",
            "|    0   N/A  N/A    792015      C   python                            433MiB |\n",
            "|    0   N/A  N/A   2577963      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "|    1   N/A  N/A   2577963      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "|    1   N/A  N/A   2990695      C   ...ers-playground/bin/python     1137MiB |\n",
            "|    1   N/A  N/A   3642995      C   ...ouda/anaconda3/bin/python      685MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "### Check gpu specs\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FTf_OdfEz8kI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset newyorker_caption_contest (/home/kushinm/.cache/huggingface/datasets/jmhessel___newyorker_caption_contest/explanation/1.0.0/43749f7b7c0566b3b1bb518ee81866c0ae27f310ad1b3405918479d6eafcaabe)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Two women are looking out a window. There is snow outside, and there is a snowman with human arms.\n"
          ]
        }
      ],
      "source": [
        "# Load new yorker dataset with the right split\n",
        "from datasets import load_dataset,Dataset,Image\n",
        "ds = load_dataset(\"jmhessel/newyorker_caption_contest\", 'explanation',split=\"train\")\n",
        "sample = ds[0]\n",
        "display(sample[\"image\"].resize((256, 256)))\n",
        "print(sample[\"image_description\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# # from PIL import Image\n",
        "\n",
        "\n",
        "# # Define a function to convert image files to 3D arrays\n",
        "# def convert_to_array(image_file):\n",
        "#     if len(image_file.shape) != 3:\n",
        "#         image_file = np.stack((image_file,) * 3, axis=-1)\n",
        "#     return image_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ims = [np.array(ds[i]['image']) for i in range(len(ds))]\n",
        "# ims_3d = [convert_to_array(im) for im in ims]\n",
        "# caps = [ds[i]['image_description'] for i in range(len(ds))]\n",
        "\n",
        "# ds_altered = Dataset.from_dict({'image':ims_3d, 'caption':caps})\n",
        "# ds_altered = ds_altered.cast_column(\"image\", Image())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Load the dataset\n",
        "\n",
        "\n",
        "# # Convert each image file in the dataset to a 3D array and make sure it is saved back to the dataset\n",
        "# for i,example in enumerate(ds):\n",
        "#     ds[i]['image'] = convert_to_array(np.array(ds[i]['image']))\n",
        "# dataset = ds.map(lambda example: {'image': convert_to_array(example['image'])}, batched=True)\n",
        "# # for i,example in enumerate(ds):\n",
        "# #     ds[i]['image'] = convert_to_array(np.array(ds[i]['image']))\n",
        "# # dataset = ds.map(lambda example: {'image': convert_to_array(example['image'])}, batched=True)\n",
        "\n",
        "# # Save the new dataset\n",
        "# # dataset.save_to_disk('path/to/new/dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V1uUVjQz8kI"
      },
      "source": [
        "To get the weights you need to you'll need to [go to the model card](https://huggingface.co/CompVis/stable-diffusion-v1-4-original), read the license and tick the checkbox if you agree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PbMtzkytz8kI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid.\n",
            "Your token has been saved to /home/kushinm/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "### login to huggingface hub\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(token='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') ## add token here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vnnbNNycz8kI"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "ckpt_path = hf_hub_download(repo_id=\"CompVis/stable-diffusion-v-1-4-original\", filename=\"sd-v1-4-full-ema.ckpt\", use_auth_token=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8VDyuQxz8kJ"
      },
      "source": [
        "Set your parameters below depending on your GPU setup, the settings below were used for training on a 2xA6000 machine, (the A6000 has 48GB of VRAM). On this set up good results are achieved in around 6 hours.\n",
        "\n",
        "You can make up for using smaller batches or fewer gpus by accumulating batches:\n",
        "\n",
        "`total batch size = batach size * n gpus * accumulate batches`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WVssEQJfz8kJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPUs: 0,1,\n"
          ]
        }
      ],
      "source": [
        "# 2xA6000:\n",
        "BATCH_SIZE = 1\n",
        "N_GPUS = 1\n",
        "ACCUMULATE_BATCHES = 2\n",
        "\n",
        "gpu_list = \",\".join((str(x) for x in range(N_GPUS))) + \",\"\n",
        "print(f\"Using GPUs: {gpu_list}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpu_list = '1,'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "w7sLO53fz8kJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Global seed set to 23\n",
            "Running on GPUs 1,\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "Keeping EMAs of 688.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'visual_projection.weight', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'logit_scale', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'text_projection.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.bias']\n",
            "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Attempting to load state from /home/kushinm/.cache/huggingface/hub/models--CompVis--stable-diffusion-v-1-4-original/snapshots/f0bb45b49990512c454cf2c5670b0952ef2f9c71/sd-v1-4-full-ema.ckpt\n",
            "Found nested key 'state_dict' in checkpoint, loading this instead\n",
            "Monitoring val/loss as checkpoint metric.\n",
            "Merged modelckpt-cfg: \n",
            "{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2023-04-29T03-19-46_newyorker/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': None, 'save_top_k': -1, 'every_n_train_steps': 2000}}\n",
            "/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:432: UserWarning: ModelCheckpoint(save_last=True, save_top_k=None, monitor=None) is a redundant configuration. You can save the last checkpoint with ModelCheckpoint(save_top_k=None, monitor=None).\n",
            "  rank_zero_warn(\n",
            "ModelCheckpoint(save_last=True, save_top_k=-1, monitor=None) will duplicate the last checkpoint saved.\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "Reusing dataset newyorker_caption_contest (/home/kushinm/.cache/huggingface/datasets/jmhessel___newyorker_caption_contest/explanation/1.0.0/43749f7b7c0566b3b1bb518ee81866c0ae27f310ad1b3405918479d6eafcaabe)\n",
            "/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "columns ['image', 'contest_number', 'image_location', 'image_description', 'image_uncanny_description', 'entities', 'questions', 'caption_choices', 'from_description', 'label', 'n_tokens_label', 'instance_id']\n",
            "Reusing dataset newyorker_caption_contest (/home/kushinm/.cache/huggingface/datasets/jmhessel___newyorker_caption_contest/explanation/1.0.0/43749f7b7c0566b3b1bb518ee81866c0ae27f310ad1b3405918479d6eafcaabe)\n",
            "columns ['image', 'contest_number', 'image_location', 'image_description', 'image_uncanny_description', 'entities', 'questions', 'caption_choices', 'from_description', 'label', 'n_tokens_label', 'instance_id']\n",
            "#### Data #####\n",
            "train, Dataset, 2340\n",
            "validation, TextOnly, 8\n",
            "accumulate_grad_batches = 5\n",
            "++++ NOT USING LR SCALING ++++\n",
            "Setting learning rate to 1.00e-04\n",
            "Global seed set to 23\n",
            "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All DDP processes registered. Starting ddp with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
            "Training the full unet\n",
            "Setting up LambdaLR scheduler...\n",
            "Project config\n",
            "model:\n",
            "  base_learning_rate: 0.0001\n",
            "  target: ldm.models.diffusion.ddpm.LatentDiffusion\n",
            "  params:\n",
            "    linear_start: 0.00085\n",
            "    linear_end: 0.012\n",
            "    num_timesteps_cond: 1\n",
            "    log_every_t: 200\n",
            "    timesteps: 1000\n",
            "    first_stage_key: image\n",
            "    cond_stage_key: txt\n",
            "    image_size: 64\n",
            "    channels: 4\n",
            "    cond_stage_trainable: false\n",
            "    conditioning_key: crossattn\n",
            "    scale_factor: 0.18215\n",
            "    scheduler_config:\n",
            "      target: ldm.lr_scheduler.LambdaLinearScheduler\n",
            "      params:\n",
            "        warm_up_steps:\n",
            "        - 1\n",
            "        cycle_lengths:\n",
            "        - 10000000000000\n",
            "        f_start:\n",
            "        - 1.0e-06\n",
            "        f_max:\n",
            "        - 1.0\n",
            "        f_min:\n",
            "        - 1.0\n",
            "    unet_config:\n",
            "      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n",
            "      params:\n",
            "        image_size: 32\n",
            "        in_channels: 4\n",
            "        out_channels: 4\n",
            "        model_channels: 320\n",
            "        attention_resolutions:\n",
            "        - 4\n",
            "        - 2\n",
            "        - 1\n",
            "        num_res_blocks: 2\n",
            "        channel_mult:\n",
            "        - 1\n",
            "        - 2\n",
            "        - 4\n",
            "        - 4\n",
            "        num_heads: 8\n",
            "        use_spatial_transformer: true\n",
            "        transformer_depth: 1\n",
            "        context_dim: 768\n",
            "        use_checkpoint: true\n",
            "        legacy: false\n",
            "    first_stage_config:\n",
            "      target: ldm.models.autoencoder.AutoencoderKL\n",
            "      ckpt_path: models/first_stage_models/kl-f8/model.ckpt\n",
            "      params:\n",
            "        embed_dim: 4\n",
            "        monitor: val/rec_loss\n",
            "        ddconfig:\n",
            "          double_z: true\n",
            "          z_channels: 4\n",
            "          resolution: 256\n",
            "          in_channels: 3\n",
            "          out_ch: 3\n",
            "          ch: 128\n",
            "          ch_mult:\n",
            "          - 1\n",
            "          - 2\n",
            "          - 4\n",
            "          - 4\n",
            "          num_res_blocks: 2\n",
            "          attn_resolutions: []\n",
            "          dropout: 0.0\n",
            "        lossconfig:\n",
            "          target: torch.nn.Identity\n",
            "    cond_stage_config:\n",
            "      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder\n",
            "data:\n",
            "  target: main.DataModuleFromConfig\n",
            "  params:\n",
            "    batch_size: 1\n",
            "    num_workers: 4\n",
            "    num_val_workers: 0\n",
            "    train:\n",
            "      target: ldm.data.simple.hf_dataset\n",
            "      params:\n",
            "        name: jmhessel/newyorker_caption_contest\n",
            "        image_transforms:\n",
            "        - target: torchvision.transforms.Resize\n",
            "          params:\n",
            "            size: 512\n",
            "            interpolation: 3\n",
            "        - target: torchvision.transforms.RandomCrop\n",
            "          params:\n",
            "            size: 512\n",
            "        - target: torchvision.transforms.RandomHorizontalFlip\n",
            "    validation:\n",
            "      target: ldm.data.simple.TextOnly\n",
            "      params:\n",
            "        captions:\n",
            "        - A pokemon with green eyes, large wings, and a hat\n",
            "        - A cute bunny rabbit\n",
            "        - Yoda\n",
            "        - An epic landscape photo of a mountain\n",
            "        output_size: 512\n",
            "        n_gpus: 2\n",
            "\n",
            "Lightning config\n",
            "find_unused_parameters: false\n",
            "modelcheckpoint:\n",
            "  params:\n",
            "    every_n_train_steps: 2000\n",
            "    save_top_k: -1\n",
            "    monitor: null\n",
            "callbacks:\n",
            "  image_logger:\n",
            "    target: main.ImageLogger\n",
            "    params:\n",
            "      batch_frequency: 2000\n",
            "      max_images: 4\n",
            "      increase_log_steps: false\n",
            "      log_first_step: true\n",
            "      log_all_val: true\n",
            "      log_images_kwargs:\n",
            "        use_ema_scope: true\n",
            "        inpaint: false\n",
            "        plot_progressive_rows: false\n",
            "        plot_diffusion_rows: false\n",
            "        'N': 4\n",
            "        unconditional_guidance_scale: 3.0\n",
            "        unconditional_guidance_label:\n",
            "        - ''\n",
            "trainer:\n",
            "  benchmark: true\n",
            "  num_sanity_val_steps: 0\n",
            "  accumulate_grad_batches: 5\n",
            "  accelerator: ddp\n",
            "  check_val_every_n_epoch: 10\n",
            "  gpus: 1,\n",
            "\n",
            "\n",
            "  | Name              | Type               | Params\n",
            "---------------------------------------------------------\n",
            "0 | model             | DiffusionWrapper   | 859 M \n",
            "1 | model_ema         | LitEma             | 0     \n",
            "2 | first_stage_model | AutoencoderKL      | 83.7 M\n",
            "3 | cond_stage_model  | FrozenCLIPEmbedder | 123 M \n",
            "---------------------------------------------------------\n",
            "859 M     Trainable params\n",
            "206 M     Non-trainable params\n",
            "1.1 B     Total params\n",
            "4,264.941 Total estimated model params size (MB)\n",
            "/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "Epoch 0:   0%|                               | 0/2340 [00:00<00:00, 6413.31it/s]en example <PIL.JpegImagePlugin.JpegImageFile image mode=L size=323x217 at 0x7F740011FA00>\n",
            "en example <PIL.JpegImagePlugin.JpegImageFile image mode=L size=468x403 at 0x7F740012A340>\n",
            "en example <PIL.JpegImagePlugin.JpegImageFile image mode=L size=716x800 at 0x7F740011F6A0>\n",
            "en example <PIL.JpegImagePlugin.JpegImageFile image mode=L size=800x543 at 0x7F78D6DB8970>\n",
            "en example <PIL.JpegImagePlugin.JpegImageFile image mode=L size=647x500 at 0x7F78D6DB8610>\n",
            "en example <PIL.JpegImagePlugin.JpegImageFile image mode=L size=800x621 at 0x7F78D6DB7580>\n",
            "en example <PIL.JpegImagePlugin.JpegImageFile image mode=L size=465x362 at 0x7F740011FD60>\n",
            "en example <PIL.JpegImagePlugin.JpegImageFile image mode=L size=800x695 at 0x7F78D6C4F190>\n",
            "en example <PIL.JpegImagePlugin.JpegImageFile image mode=L size=500x453 at 0x7F78D6DB8D00>\n",
            "Summoning checkpoint.\n",
            "en example <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=800x686 at 0x7F78D6C4B670>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 923, in <module>\n",
            "    raise err\n",
            "  File \"main.py\", line 905, in <module>\n",
            "    trainer.fit(model, data)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 553, in fit\n",
            "    self._run(model)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 918, in _run\n",
            "    self._dispatch()\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _dispatch\n",
            "    self.accelerator.start_training(self)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
            "    self.training_type_plugin.start_training(trainer)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in start_training\n",
            "    self._results = trainer.run_stage()\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 996, in run_stage\n",
            "    return self._run_train()\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1045, in _run_train\n",
            "    self.fit_loop.run()\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
            "    epoch_output = self.epoch_loop.run(train_dataloader)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 130, in advance\n",
            "    batch_output = self.batch_loop.run(batch, self.iteration_count, self._dataloader_idx)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 101, in run\n",
            "    super().run(batch, batch_idx, dataloader_idx)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 148, in advance\n",
            "    result = self._run_optimization(batch_idx, split_batch, opt_idx, optimizer)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 194, in _run_optimization\n",
            "    closure()\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 236, in _training_step_and_backward_closure\n",
            "    result = self.training_step_and_backward(split_batch, batch_idx, opt_idx, optimizer, hiddens)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 537, in training_step_and_backward\n",
            "    result = self._training_step(split_batch, batch_idx, opt_idx, hiddens)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 307, in _training_step\n",
            "    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 193, in training_step\n",
            "    return self.training_type_plugin.training_step(*step_kwargs.values())\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py\", line 383, in training_step\n",
            "    return self.model(*args, **kwargs)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/parallel/distributed.py\", line 1008, in forward\n",
            "    output = self._run_ddp_forward(*inputs, **kwargs)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/parallel/distributed.py\", line 969, in _run_ddp_forward\n",
            "    return module_to_run(*inputs[0], **kwargs[0])\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/overrides/base.py\", line 82, in forward\n",
            "    output = self.module.training_step(*inputs, **kwargs)\n",
            "  File \"/home/kushinm/repos/SD-NY-finetuning/ldm/models/diffusion/ddpm.py\", line 406, in training_step\n",
            "    loss, loss_dict = self.shared_step(batch)\n",
            "  File \"/home/kushinm/repos/SD-NY-finetuning/ldm/models/diffusion/ddpm.py\", line 872, in shared_step\n",
            "    x, c = self.get_input(batch, self.first_stage_key)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/home/kushinm/repos/SD-NY-finetuning/ldm/models/diffusion/ddpm.py\", line 725, in get_input\n",
            "    encoder_posterior = self.encode_first_stage(x)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/home/kushinm/repos/SD-NY-finetuning/ldm/models/diffusion/ddpm.py\", line 869, in encode_first_stage\n",
            "    return self.first_stage_model.encode(x)\n",
            "  File \"/home/kushinm/repos/SD-NY-finetuning/ldm/models/autoencoder.py\", line 325, in encode\n",
            "    h = self.encoder(x)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/home/kushinm/repos/SD-NY-finetuning/ldm/modules/diffusionmodules/model.py\", line 439, in forward\n",
            "    hs = [self.conv_in(x)]\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 457, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/home/kushinm/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 453, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "RuntimeError: Given groups=1, weight of size [128, 3, 3, 3], expected input[1, 1, 512, 512] to have 3 channels, but got 1 channels instead\n"
          ]
        }
      ],
      "source": [
        "# Run training\n",
        "!(python main.py \\\n",
        "    -t \\\n",
        "    --base 'configs/stable-diffusion/newyorker.yaml' \\\n",
        "    --gpus \"$gpu_list\" \\\n",
        "    --scale_lr False \\\n",
        "    --num_nodes 1 \\\n",
        "    --check_val_every_n_epoch 10 \\\n",
        "    --finetune_from \"$ckpt_path\" \\\n",
        "    data.params.batch_size=\"$BATCH_SIZE\" \\\n",
        "    lightning.trainer.accumulate_grad_batches=\"$ACCUMULATE_BATCHES\" \\\n",
        "    data.params.validation.params.n_gpus=\"$N_GPUS\" \\\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk9wHFKgz8kJ"
      },
      "outputs": [],
      "source": [
        "# Run the model\n",
        "!(python scripts/txt2img.py \\\n",
        "    --prompt 'robotic cat with wings' \\\n",
        "    --outdir 'outputs/generated_pokemon' \\\n",
        "    --H 300 --W 300 \\\n",
        "    --n_samples 1 \\\n",
        "    --config 'configs/stable-diffusion/newyorker.yaml' \\\n",
        "    --ckpt 'path/to/your/checkpoint')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
